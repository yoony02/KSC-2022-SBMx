{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import operator\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(save_dir='yoochoose_temp')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--save-dir', default='yoochoose_temp', help='save directory name')\n",
    "opt = parser.parse_args([])\n",
    "print(opt)\n",
    "\n",
    "os.makedirs(f'../{opt.save_dir}_4', exist_ok=True)\n",
    "os.makedirs(f'../{opt.save_dir}_64', exist_ok=True)\n",
    "\n",
    "dataset = '../raw/yoochoose-clicks.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Starting @ 2022-10-10 16:03:35.855900s\n",
      "-- Reading data @ 2022-10-10 16:10:58.035800s\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Starting @ %ss\" % datetime.datetime.now())\n",
    "\n",
    "with open(dataset, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    sess_clicks = {}\n",
    "    sess_date = {}\n",
    "    ctr = 0\n",
    "    curid = -1\n",
    "    curdate = None\n",
    "    for data in reader:\n",
    "        sessid = data[0]\n",
    "        if curdate and not curid == sessid:\n",
    "            date = ''\n",
    "            date = time.mktime(time.strptime(curdate[:19], '%Y-%m-%dT%H:%M:%S'))\n",
    "            sess_date[curid] = date\n",
    "        curid = sessid\n",
    "        item = data[2]\n",
    "        curdate = ''\n",
    "        curdate = data[1]\n",
    "\n",
    "        if sessid in sess_clicks:\n",
    "            sess_clicks[sessid] += [item]\n",
    "        else:\n",
    "            sess_clicks[sessid] = [item]\n",
    "        ctr += 1\n",
    "    date = time.mktime(time.strptime(curdate[:19], '%Y-%m-%dT%H:%M:%S'))\n",
    "    # add\n",
    "    for i in list(sess_clicks):\n",
    "        sorted_clicks = sorted(sess_clicks[i], key=operator.itemgetter(1))\n",
    "        sess_clicks[i] = [c for c in sorted_clicks]\n",
    "    sess_date[curid] = date\n",
    "print(\"-- Reading data @ %ss\" % datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out length shorter than 2\n",
    "for s in list(sess_clicks):\n",
    "    if len(sess_clicks[s]) < 2 :\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "\n",
    "# Counter number of times each appears\n",
    "iid_counts = {}\n",
    "for s in sess_clicks:\n",
    "    seq = sess_clicks[s]\n",
    "    for iid in seq:\n",
    "        if iid in iid_counts:\n",
    "            iid_counts[iid] += 1\n",
    "        else:\n",
    "            iid_counts[iid] = 1\n",
    "\n",
    "sorted_counts = sorted(iid_counts.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting date 1411927199.0\n",
      "# train sessions: 7966257\n",
      "# test sessions: 15324\n",
      "train sessions example: [('171168', 1396288832.0), ('345618', 1396288875.0), ('263073', 1396288902.0)]\n",
      "test sessions example: [('11532683', 1411927253.0), ('11464959', 1411927271.0), ('11296119', 1411927295.0)]\n",
      "-- Splitting train set and test set @ 2022-10-10 16:12:20.225155s\n"
     ]
    }
   ],
   "source": [
    "length = len(sess_clicks)\n",
    "for s in list(sess_clicks):\n",
    "    curseq = sess_clicks[s]\n",
    "    filseq = list(filter(lambda i: iid_counts[i] >= 5, curseq))\n",
    "\n",
    "    if len(filseq) < 2 :\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "    else:\n",
    "        sess_clicks[s] = filseq\n",
    "\n",
    "dates = list(sess_date.items())\n",
    "maxdate = dates[0][1]\n",
    "\n",
    "for _, date in dates:\n",
    "    if maxdate < date:\n",
    "        maxdate = date\n",
    "\n",
    "# 7 days for test\n",
    "splitdate = 0\n",
    "splitdate = maxdate - 86400 * 1\n",
    "\n",
    "print('Splitting date', splitdate)      # Yoochoose: ('Split date', 1411930799.0)\n",
    "tra_sess = filter(lambda x: x[1] < splitdate, dates)\n",
    "tes_sess = filter(lambda x: x[1] > splitdate, dates)\n",
    "\n",
    "# Sort sessions by date\n",
    "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))     # [(session_id, timestamp), (), ]\n",
    "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))     # [(session_id, timestamp), (), ]\n",
    "print(f'# train sessions: {len(tra_sess)}')    # 186670    # 7966257\n",
    "print(f'# test sessions: {len(tes_sess)}')    # 15979     # 15324\n",
    "print(f'train sessions example: {tra_sess[:3]}')\n",
    "print(f'test sessions example: {tes_sess[:3]}')\n",
    "\n",
    "print(\"-- Splitting train set and test set @ %ss\" % datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1/4 train sessions before preprocess: 1991564\n",
      "# 1/64 train sessions before preprocess : 124472\n",
      "-- Splitting train set and test set @ 2022-10-10 16:12:20.306506s\n"
     ]
    }
   ],
   "source": [
    "# split train dataset 1/4 and 1/64\n",
    "split4 = int(len(tra_sess) / 4)\n",
    "split64 = int(len(tra_sess) / 64)\n",
    "tra_sess4 = tra_sess[-split4:]\n",
    "tra_sess64 = tra_sess[-split64:]\n",
    "\n",
    "print(f\"# 1/4 train sessions before preprocess: {len(tra_sess4)}\")\n",
    "print(f\"# 1/64 train sessions before preprocess : {len(tra_sess64)}\")\n",
    "\n",
    "print(\"-- Splitting train set and test set @ %ss\" % datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocess yoochoose 1/4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict, item_cnt = {}, {}\n",
    "\n",
    "# train\n",
    "train_ids, train_seqs, train_dates = [], [], []\n",
    "item_ctr = 1\n",
    "for s, date in tra_sess4:\n",
    "    seq = sess_clicks[s]\n",
    "    outseq = []\n",
    "    for i in seq:\n",
    "        if i in item_dict:\n",
    "            outseq += [item_dict[i]]\n",
    "            item_cnt[item_dict[i]] += 1\n",
    "        else:\n",
    "            outseq += [item_ctr]\n",
    "            item_dict[i] = item_ctr\n",
    "            item_cnt[item_dict[i]] = 1\n",
    "            item_ctr += 1\n",
    "    if len(outseq) < 2: \n",
    "        continue\n",
    "    train_ids += [s]\n",
    "    train_dates += [date]\n",
    "    train_seqs += [outseq]\n",
    "\n",
    "# test\n",
    "test_ids = []\n",
    "test_seqs = []\n",
    "test_dates = []\n",
    "for s, date in tes_sess:\n",
    "    seq = sess_clicks[s]\n",
    "    outseq = []\n",
    "    for i in seq:\n",
    "        if i in item_dict:\n",
    "            outseq += [item_dict[i]]\n",
    "    if len(outseq) < 2:\n",
    "        continue\n",
    "    test_ids += [s]\n",
    "    test_dates += [date]\n",
    "    test_seqs += [outseq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seqs(iseqs, idates, train=True):\n",
    "    out_seqs, labs = [], []\n",
    "    \n",
    "    if train:\n",
    "        out_dates, ids = [], []\n",
    "\n",
    "        for id, seq, date in zip(range(len(iseqs)), iseqs, idates):\n",
    "            for i in range(1, len(seq)):\n",
    "                tar = seq[-i]\n",
    "                labs += [tar]\n",
    "                out_seqs += [seq[:-i]]\n",
    "                out_dates += [date]\n",
    "                ids += [id]\n",
    "        return out_seqs, out_dates, labs, ids\n",
    "    else:\n",
    "        for seq in iseqs:\n",
    "            labs += [seq[-1]]\n",
    "            out_seqs += [seq[:-1]]\n",
    "        return out_seqs, labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_seqs, tra_dates, tra_labs, tra_ids = process_seqs(train_seqs, train_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[372, 1415, 6905, 14192, 7827, 4582, 4288, 2666],\n",
       " [372, 1415, 6905, 14192, 7827, 4582, 4288],\n",
       " [372, 1415, 6905, 14192, 7827, 4582],\n",
       " [372, 1415, 6905, 14192, 7827],\n",
       " [372, 1415, 6905, 14192],\n",
       " [372, 1415, 6905],\n",
       " [372, 1415],\n",
       " [372],\n",
       " [30218],\n",
       " [29484, 29419, 29299],\n",
       " [29484, 29419],\n",
       " [29484],\n",
       " [30163],\n",
       " [30297],\n",
       " [7983],\n",
       " [29299],\n",
       " [1659, 357, 2661, 3548, 4048],\n",
       " [1659, 357, 2661, 3548],\n",
       " [1659, 357, 2661],\n",
       " [1659, 357],\n",
       " [1659],\n",
       " [5885],\n",
       " [29271],\n",
       " [30488, 30174, 30164, 30164, 29295, 168, 29220, 29299, 4699, 14605],\n",
       " [30488, 30174, 30164, 30164, 29295, 168, 29220, 29299, 4699],\n",
       " [30488, 30174, 30164, 30164, 29295, 168, 29220, 29299],\n",
       " [30488, 30174, 30164, 30164, 29295, 168, 29220],\n",
       " [30488, 30174, 30164, 30164, 29295, 168],\n",
       " [30488, 30174, 30164, 30164, 29295],\n",
       " [30488, 30174, 30164, 30164],\n",
       " [30488, 30174, 30164],\n",
       " [30488, 30174],\n",
       " [30488],\n",
       " [25035, 30363, 30218, 30150],\n",
       " [25035, 30363, 30218],\n",
       " [25035, 30363],\n",
       " [25035],\n",
       " [30306, 30565, 30213, 30218, 30375, 30411],\n",
       " [30306, 30565, 30213, 30218, 30375],\n",
       " [30306, 30565, 30213, 30218],\n",
       " [30306, 30565, 30213],\n",
       " [30306, 30565],\n",
       " [30306],\n",
       " [29235, 29235, 29271, 29271, 29271, 29271, 29762, 29762, 29344, 29344, 29507],\n",
       " [29235, 29235, 29271, 29271, 29271, 29271, 29762, 29762, 29344, 29344],\n",
       " [29235, 29235, 29271, 29271, 29271, 29271, 29762, 29762, 29344],\n",
       " [29235, 29235, 29271, 29271, 29271, 29271, 29762, 29762],\n",
       " [29235, 29235, 29271, 29271, 29271, 29271, 29762],\n",
       " [29235, 29235, 29271, 29271, 29271, 29271],\n",
       " [29235, 29235, 29271, 29271, 29271],\n",
       " [29235, 29235, 29271, 29271],\n",
       " [29235, 29235, 29271],\n",
       " [29235, 29235],\n",
       " [29235],\n",
       " [29285, 29663],\n",
       " [29285],\n",
       " [29296, 29235, 29296, 1445],\n",
       " [29296, 29235, 29296],\n",
       " [29296, 29235],\n",
       " [29296],\n",
       " [30111],\n",
       " [30375, 30173],\n",
       " [30375],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398,\n",
       "  23388,\n",
       "  26530,\n",
       "  1733,\n",
       "  28805,\n",
       "  1323,\n",
       "  2545],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398,\n",
       "  23388,\n",
       "  26530,\n",
       "  1733,\n",
       "  28805,\n",
       "  1323],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398,\n",
       "  23388,\n",
       "  26530,\n",
       "  1733,\n",
       "  28805],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398,\n",
       "  23388,\n",
       "  26530,\n",
       "  1733],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398,\n",
       "  23388,\n",
       "  26530],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398,\n",
       "  23388],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869,\n",
       "  398],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307,\n",
       "  29869],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398,\n",
       "  29307],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33,\n",
       "  7398],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688,\n",
       "  33],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691,\n",
       "  1688],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896,\n",
       "  691],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283,\n",
       "  896],\n",
       " [29296,\n",
       "  29411,\n",
       "  29484,\n",
       "  747,\n",
       "  28441,\n",
       "  12179,\n",
       "  29235,\n",
       "  29271,\n",
       "  29235,\n",
       "  1424,\n",
       "  1283,\n",
       "  1283],\n",
       " [29296, 29411, 29484, 747, 28441, 12179, 29235, 29271, 29235, 1424, 1283],\n",
       " [29296, 29411, 29484, 747, 28441, 12179, 29235, 29271, 29235, 1424],\n",
       " [29296, 29411, 29484, 747, 28441, 12179, 29235, 29271, 29235],\n",
       " [29296, 29411, 29484, 747, 28441, 12179, 29235, 29271],\n",
       " [29296, 29411, 29484, 747, 28441, 12179, 29235],\n",
       " [29296, 29411, 29484, 747, 28441, 12179],\n",
       " [29296, 29411, 29484, 747, 28441],\n",
       " [29296, 29411, 29484, 747],\n",
       " [29296, 29411, 29484],\n",
       " [29296, 29411],\n",
       " [29296],\n",
       " [1862],\n",
       " [29336, 29220, 29299],\n",
       " [29336, 29220],\n",
       " [29336],\n",
       " [101],\n",
       " [30151, 30151],\n",
       " [30151],\n",
       " [30149],\n",
       " [28805],\n",
       " [29663, 366],\n",
       " [29663]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_seqs[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_seqs, tes_labs = process_seqs(test_seqs, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30618] 30579 [30653, 1290, 1291, 1291] 30579\n"
     ]
    }
   ],
   "source": [
    "print(max(tes_seqs), max(tes_labs), max(tra_seqs), max(tes_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30653"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(item_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/64 # train sessions 6145883, ex. ([[1], [2], [4, 5]], [1, 3, 6])\n",
      "1/64 # test sessions 15317, ex. ([[17788, 29299, 5885], [30153, 29576, 30148, 30151], [2628, 185]], [350, 30148, 359])\n",
      "1/64 # train clicks 8137447\n",
      "1/64 # items 30653\n",
      "1/64 avg. length : 4.710282802324743\n"
     ]
    }
   ],
   "source": [
    "print(f\"1/4 # train sessions {len(tra_seqs)}, ex. {tra_seqs[:3], tra_labs[:3]}\")\n",
    "print(f\"1/4 # test sessions {len(tes_seqs)}, ex. {tes_seqs[:3], tes_labs[:3]}\")\n",
    "print(f\"1/4 # train clicks {sum(item_cnt.values())}\")\n",
    "print(f\"1/4 # items {len(item_cnt.keys())}\")\n",
    "print(f\"1/4 avg. length : {sum(map(len, tra_seqs)) / len(tra_seqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra = (tra_seqs, tra_labs)\n",
    "tes = (tes_seqs, tes_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 30653\n"
     ]
    }
   ],
   "source": [
    "print(min(item_cnt.keys()), max(item_cnt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tra, open(f'../{opt.save_dir}_4/train.txt', 'wb'))\n",
    "pickle.dump(tes, open(f'../{opt.save_dir}_4/test.txt', 'wb'))\n",
    "pickle.dump(len(item_cnt.keys()) + 1, open(f'../{opt.save_dir}_4/n_node.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity dict\n",
    "total_ctr = sum(item_cnt.values())\n",
    "pop_dict = {key : (value / total_ctr) for key, value in item_cnt.items()}\n",
    "\n",
    "pickle.dump(pop_dict, open(f\"../{opt.save_dir}_4/pop_dict.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = sorted(item_cnt.items(), reverse=True, key=lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(item_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# head items : 6179, # tail items : 24474\n"
     ]
    }
   ],
   "source": [
    "# head tail dict \n",
    "sorted_item_cnt = sorted(item_cnt.items(), reverse=True, key=lambda item: item[1])\n",
    "sorted_keys = np.array(sorted_item_cnt)[:, 0].astype(int)\n",
    "sorted_values = np.array(sorted_item_cnt)[:, 1]\n",
    "\n",
    "split_point = int(len(sorted_keys) * 0.2)\n",
    "point_cnt_value = sorted_values[split_point]\n",
    "split_idx = [i for i, cnt in enumerate(sorted_values) if cnt == (point_cnt_value-1)][0]\n",
    "\n",
    "ht_dict = dict()\n",
    "ht_dict['head'] = sorted_keys[:split_idx]\n",
    "ht_dict['tail'] = sorted_keys[split_idx:]\n",
    "\n",
    "print(f'# head items : {len(ht_dict[\"head\"])}, # tail items : {len(ht_dict[\"tail\"])}')\n",
    "pickle.dump(ht_dict, open(f'../{opt.save_dir}_4/ht_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess 1/64 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict, item_cnt = {}, {}\n",
    "\n",
    "# train\n",
    "train_ids, train_seqs, train_dates = [], [], []\n",
    "item_ctr = 1\n",
    "for s, date in tra_sess64:\n",
    "    seq = sess_clicks[s]\n",
    "    outseq = []\n",
    "    for i in seq:\n",
    "        if i in item_dict:\n",
    "            outseq += [item_dict[i]]\n",
    "            item_cnt[item_dict[i]] += 1\n",
    "        else:\n",
    "            outseq += [item_ctr]\n",
    "            item_dict[i] = item_ctr\n",
    "            item_cnt[item_dict[i]] = 1\n",
    "            item_ctr += 1\n",
    "    if len(outseq) < 2: \n",
    "        continue\n",
    "    train_ids += [s]\n",
    "    train_dates += [date]\n",
    "    train_seqs += [outseq]\n",
    "\n",
    "# test\n",
    "test_ids = []\n",
    "test_seqs = []\n",
    "test_dates = []\n",
    "for s, date in tes_sess:\n",
    "    seq = sess_clicks[s]\n",
    "    outseq = []\n",
    "    for i in seq:\n",
    "        if i in item_dict:\n",
    "            outseq += [item_dict[i]]\n",
    "    if len(outseq) < 2:\n",
    "        continue\n",
    "    test_ids += [s]\n",
    "    test_dates += [date]\n",
    "    test_seqs += [outseq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seqs(iseqs, idates, train=True):\n",
    "    out_seqs, labs = [], []\n",
    "    \n",
    "    if train:\n",
    "        out_dates, ids = [], []\n",
    "\n",
    "        for id, seq, date in zip(range(len(iseqs)), iseqs, idates):\n",
    "            for i in range(1, len(seq)):\n",
    "                tar = seq[-i]\n",
    "                labs += [tar]\n",
    "                out_seqs += [seq[:-i]]\n",
    "                out_dates += [date]\n",
    "                ids += [id]\n",
    "        return out_seqs, out_dates, labs, ids\n",
    "    else:\n",
    "        for seq in iseqs:\n",
    "            labs += [seq[-1]]\n",
    "            out_seqs += [seq[:-1]]\n",
    "        return out_seqs, labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_seqs, tra_dates, tra_labs, tra_ids = process_seqs(train_seqs, train_dates)\n",
    "tes_seqs, tes_labs = process_seqs(test_seqs, None, False)\n",
    "print(max(tes_seqs), max(tes_labs), max(tra_seqs), max(tes_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(item_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"1/64 # train sessions {len(tra_seqs)}, ex. {tra_seqs[:3], tra_labs[:3]}\")\n",
    "print(f\"1/64 # test sessions {len(tes_seqs)}, ex. {tes_seqs[:3], tes_labs[:3]}\")\n",
    "print(f\"1/64 # train clicks {sum(item_cnt.values())}\")\n",
    "print(f\"1/64 # items {len(item_cnt.keys())}\")\n",
    "print(f\"1/64 avg. length : {sum(map(len, tra_seqs)) / len(tra_seqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra = (tra_seqs, tra_labs)\n",
    "tes = (tes_seqs, tes_labs)\n",
    "print(min(item_cnt.keys()), max(item_cnt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tra, open(f'../{opt.save_dir}_64/train.txt', 'wb'))\n",
    "pickle.dump(tes, open(f'../{opt.save_dir}_64/test.txt', 'wb'))\n",
    "pickle.dump(len(item_cnt.keys()) + 1, open(f'../{opt.save_dir}_64/n_node.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity dict\n",
    "total_ctr = sum(item_cnt.values())\n",
    "pop_dict = {key : (value / total_ctr) for key, value in item_cnt.items()}\n",
    "\n",
    "pickle.dump(pop_dict, open(f\"../{opt.save_dir}_64/pop_dict.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head tail dict \n",
    "sorted_item_cnt = sorted(item_cnt.items(), reverse=True, key=lambda item: item[1])\n",
    "sorted_keys = np.array(sorted_item_cnt)[:, 0].astype(int)\n",
    "sorted_values = np.array(sorted_item_cnt)[:, 1]\n",
    "\n",
    "split_point = int(len(sorted_keys) * 0.2)\n",
    "point_cnt_value = sorted_values[split_point]\n",
    "split_idx = [i for i, cnt in enumerate(sorted_values) if cnt == (point_cnt_value-1)][0]\n",
    "\n",
    "ht_dict = dict()\n",
    "ht_dict['head'] = sorted_keys[:split_idx]\n",
    "ht_dict['tail'] = sorted_keys[split_idx:]\n",
    "\n",
    "print(f'# head items : {len(ht_dict[\"head\"])}, # tail items : {len(ht_dict[\"tail\"])}')\n",
    "pickle.dump(ht_dict, open(f'../{opt.save_dir}_64/ht_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ht_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mht_dict\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ht_dict' is not defined"
     ]
    }
   ],
   "source": [
    "ht_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
